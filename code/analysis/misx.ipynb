{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import truncnorm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import datetime\n",
    "import tqdm\n",
    "import sys\n",
    "import os\n",
    "\n",
    "def flatten_list(list_array):\n",
    "    return list(itertools.chain(*list_array))\n",
    "\n",
    "sys.path.insert(0,\"../\")\n",
    "from global_config import config\n",
    "\n",
    "results_dir           = config.get_property('results_dir')\n",
    "data_dir              = config.get_property('data_dir')\n",
    "data_db_dir           = config.get_property('data_db_dir')\n",
    "feb_hosp_records_path = os.path.join(data_db_dir, 'long_files_8_25_2021')\n",
    "path_to_save          = os.path.join(results_dir, \"real_testing\", \"community\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7p/jp6xqkvn5wb6ddl1fn0bhs980000gn/T/ipykernel_44550/1033347647.py:8: DtypeWarning: Columns (0,1,4,8) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  movement_df, ward2cluster = load_movement_df(path_to_data, True) # movement data\n"
     ]
    }
   ],
   "source": [
    "from utils.data_utils import load_movement_df, ward2size\n",
    "from utils.plot_utils import *\n",
    "\n",
    "path_to_data = os.path.join('..', '..', 'data')\n",
    "\n",
    "# load scenarios for synthetic inferences\n",
    "scenarios_df              = pd.read_csv(os.path.join(path_to_data, 'scenarios.csv'))\n",
    "movement_df, ward2cluster = load_movement_df(path_to_data, True) # movement data\n",
    "ward2size                 = ward2size(movement_df)\n",
    "ward2size                 = {r.ward_id: r.num_patients for idx_r, r in ward2size.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_min         = pd.to_datetime(\"2020-02-01\")\n",
    "date_max         = pd.to_datetime(\"2021-02-28\")\n",
    "dates_simulation = pd.date_range(start=date_min, end=date_max)\n",
    "\n",
    "γ_prior  = [0.01, 0.9]\n",
    "β_prior  = [0.001, 0.05]\n",
    "\n",
    "param_prior_dict      = {}\n",
    "param_prior_dict[\"γ\"] = γ_prior\n",
    "param_prior_dict[\"β\"] = β_prior\n",
    "\n",
    "# Agent based model settings.\n",
    "abm_settings                     = {}\n",
    "abm_settings[\"num_patients\"]     = movement_df.mrn_id.unique().shape[0]\n",
    "abm_settings[\"num_wards\"]        = movement_df.ward_id.unique().shape[0]\n",
    "abm_settings[\"num_clusters\"]     = len(set(list(ward2cluster.values())))\n",
    "abm_settings[\"dates\"]            = dates_simulation\n",
    "abm_settings[\"num_ensembles\"]    = 300\n",
    "\n",
    "# Iterated filtering settings.\n",
    "if2_settings                     = {}\n",
    "if2_settings[\"num_params\"]       = len(param_prior_dict)\n",
    "if2_settings[\"num_observations\"] = len(set(list(ward2cluster.values())))\n",
    "if2_settings[\"lambda_inf\"]       = 1.01        # Inflation for the EAKF.\n",
    "if2_settings[\"num_iters_mif\"]    = 20          # Number of iterations.\n",
    "if2_settings[\"alpha_mif\"]        = 0.8         # Variance shrinking factor.\n",
    "if2_settings[\"type_cooling\"]     = \"geometric\" # Type of cooling.\n",
    "if2_settings[\"num_ensembles\"]    = 300\n",
    "if2_settings[\"oev_variance\"]     = 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.infer_utils import *\n",
    "from utils.model_utils import model_inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_inference(\n",
    "    patients_state,\n",
    "    γ,\n",
    "    β,\n",
    "    α,\n",
    "    movement,\n",
    "    ward2size,\n",
    "    ward2cluster,\n",
    "    ρ=0.06)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "row    = scenarios_df.iloc[np.random.randint(0, len(scenarios_df))]\n",
    "ρ      = np.random.choice([4, 6, 8])\n",
    "\n",
    "θ      = {}\n",
    "θ['γ'] = row['γ']\n",
    "θ['β'] = row['β']\n",
    "θ['ρ'] = ρ / 100\n",
    "\n",
    "path_to_scenario = os.path.join('..', '..', 'results', 'synthetic_inferences', f'ρ_{ρ}%', row.name_scenario)\n",
    "name_sims_save   = f\"simulation_infer.npz\"\n",
    "sim_samples      = np.load(os.path.join(path_to_scenario, name_sims_save))\n",
    "\n",
    "cluster_positive = sim_samples['cluster_positive'][:, :, sim_samples['idx_use']]\n",
    "cluster_negative = sim_samples['cluster_negative'][:, :, sim_samples['idx_use']]\n",
    "\n",
    "obs_chunk_df         = pd.DataFrame(columns=[\"date\"] + [f\"pos_{idx_c}\" for idx_c in range(abm_settings[\"num_clusters\"])])\n",
    "obs_chunk_df[\"date\"] = abm_settings[\"dates\"]\n",
    "\n",
    "neg_chunk_df         = pd.DataFrame(columns=[\"date\"] + [f\"pos_{idx_c}\" for idx_c in range(abm_settings[\"num_clusters\"])])\n",
    "neg_chunk_df[\"date\"] = abm_settings[\"dates\"]\n",
    "\n",
    "for idx_c in range(abm_settings[\"num_clusters\"]):\n",
    "    obs_chunk_df[f\"pos_{idx_c}\"] = cluster_positive[:, idx_c]\n",
    "    neg_chunk_df[f\"pos_{idx_c}\"] = cluster_negative[:, idx_c]\n",
    "\n",
    "# Resample every week\n",
    "obs_w_chunk_df         = obs_chunk_df.set_index(\"date\").resample(\"W-Sun\").sum()\n",
    "neg_w_chunk_df         = neg_chunk_df.set_index(\"date\").resample(\"W-Sun\").sum()\n",
    "\n",
    "for idx_c in range(abm_settings[\"num_clusters\"]):\n",
    "    obs_w_chunk_df[f\"oev_{idx_c}\"]  = compute_oev(obs_w_chunk_df[f\"pos_{idx_c}\"] , var_obs=if2_settings[\"oev_variance\"] )\n",
    "    neg_w_chunk_df[f\"oev_{idx_c}\"]  = compute_oev(neg_w_chunk_df[f\"pos_{idx_c}\"] , var_obs=if2_settings[\"oev_variance\"] )\n",
    "\n",
    "\n",
    "model_use =  lambda p_state, γ_m, β_m, α_m, movement: model_inference(p_state, γ_m, β_m, α_m, movement,  ward2cluster, ward2size, θ['ρ'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'IF2_eakf_ABM' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7p/jp6xqkvn5wb6ddl1fn0bhs980000gn/T/ipykernel_44550/1959614666.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mobs_w_chunk_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_w_chunk_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs_post_all_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs_post_all_neg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpara_post_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_mean_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIF2_eakf_ABM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_use\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs_w_chunk_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_w_chunk_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmovement_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_prior_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mif2_settings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabm_settings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperturb_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'IF2_eakf_ABM' is not defined"
     ]
    }
   ],
   "source": [
    "obs_w_chunk_df, neg_w_chunk_df, obs_post_all_pos, obs_post_all_neg, para_post_all, param_iter, param_mean_iter = IF2_eakf_ABM(model_use, obs_w_chunk_df, neg_w_chunk_df, movement_df, param_prior_dict, if2_settings, abm_settings, perturb_time=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IF2_eakf_ABM(model, pos_obs_df, neg_obs_df, movement_df, param_prior, if2_settings, abm_settings, perturb_time=True):\n",
    "\n",
    "    obs_w_chunk_df = pos_obs_df\n",
    "    neg_w_chunk_df = neg_obs_df\n",
    "    cooling_factor = cooling(if2_settings[\"num_iters_mif\"], type_cool=if2_settings[\"type_cooling\"], cooling_factor=if2_settings[\"alpha_mif\"])\n",
    "\n",
    "    param_range    = np.array([v for k, v in param_prior_dict.items()])\n",
    "    std_param      = param_range[:,1] - param_range[:,0]\n",
    "    SIG            = std_param ** 2 / 4; #  initial covariance of parameters\n",
    "\n",
    "    # Perturbation is proportional to the prior range of search.\n",
    "    perturbation     = np.array([std_param % list(np.round(std_param)+0.1)]).T\n",
    "    num_steps        = len(obs_w_chunk_df)\n",
    "\n",
    "    param_mean_iter  = np.full((if2_settings[\"num_params\"],       if2_settings[\"num_iters_mif\"]+1), np.nan)                                         # Array to store posterior parameters in iterations.\n",
    "    para_post_all    = np.full((if2_settings[\"num_params\"],       if2_settings[\"num_ensembles\"], num_steps, if2_settings[\"num_iters_mif\"]), np.nan) # Array to store posterior parameters.\n",
    "    param_iter       = np.full((if2_settings[\"num_params\"],       if2_settings[\"num_ensembles\"], if2_settings[\"num_iters_mif\"]), np.nan)\n",
    "\n",
    "    obs_post_all_pos = np.full((if2_settings[\"num_observations\"], if2_settings[\"num_ensembles\"], num_steps, if2_settings[\"num_iters_mif\"]), np.nan) # Array for store posterior observations\n",
    "    obs_post_all_neg = np.full((if2_settings[\"num_observations\"], if2_settings[\"num_ensembles\"], num_steps, if2_settings[\"num_iters_mif\"]), np.nan) # Array for store posterior observations\n",
    "    p_priors_all     = np.full((if2_settings[\"num_params\"],       if2_settings[\"num_ensembles\"], if2_settings[\"num_iters_mif\"]), np.nan)\n",
    "\n",
    "    dates_assimilation     = obs_w_chunk_df.index.get_level_values(0).values\n",
    "    dates_assimilation[-1] = abm_settings[\"dates\"][-1]\n",
    "\n",
    "    α            = np.random.uniform( 1/365, 1/175, size=(abm_settings[\"num_patients\"], if2_settings[\"num_ensembles\"]))\n",
    "    perturb_time = True\n",
    "\n",
    "    print(f\"Running MIF  \\n\")\n",
    "    for n in tqdm(range(if2_settings[\"num_iters_mif\"])):\n",
    "        if n==0: # Initial IF iteration\n",
    "            p_prior               = sample_params_uniform(param_prior_dict, num_ensembles=if2_settings[\"num_ensembles\"])\n",
    "            param_mean_iter[:, n] = np.mean(p_prior, -1)\n",
    "            p_priors_all[:,:,n]   = p_prior\n",
    "\n",
    "        else:\n",
    "            params_mean           = param_mean_iter[:,n]\n",
    "            params_var            = SIG * cooling_factor[n]\n",
    "            p_prior               = sample_params_normal(param_prior_dict, params_mean, params_var, num_ensembles=if2_settings[\"num_ensembles\"])\n",
    "            p_priors_all[:,:,n]   = p_prior\n",
    "\n",
    "        patients_state    = np.zeros((abm_settings[\"num_patients\"], if2_settings[\"num_ensembles\"]))\n",
    "        param_post_time   = np.full((if2_settings[\"num_params\"], if2_settings[\"num_ensembles\"], num_steps), np.nan)\n",
    "\n",
    "        obs_post_time_pos = np.full((abm_settings[\"num_clusters\"], if2_settings[\"num_ensembles\"], num_steps), np.nan)\n",
    "        obs_post_time_neg = np.full((abm_settings[\"num_clusters\"], if2_settings[\"num_ensembles\"], num_steps), np.nan)\n",
    "\n",
    "        idx_date_update   = 0\n",
    "\n",
    "        # Init observation arrays.\n",
    "        chunk_pos_t = np.zeros((abm_settings[\"num_clusters\"], if2_settings[\"num_ensembles\"]))\n",
    "        chunk_neg_t = np.zeros((abm_settings[\"num_clusters\"], if2_settings[\"num_ensembles\"]))\n",
    "\n",
    "        for idx_date, date in enumerate(abm_settings[\"dates\"]):\n",
    "            # Integrate model\n",
    "            γ = p_prior[0, :]\n",
    "            β = p_prior[1, :]\n",
    "\n",
    "            movement_date = movement_df.loc[date]\n",
    "            patients_state, _, chunk_pos, _, chunk_neg = model(patients_state, γ, β, α, movement_date)\n",
    "\n",
    "            chunk_pos_t += chunk_pos\n",
    "            chunk_neg_t += chunk_neg\n",
    "\n",
    "            if pd.to_datetime(date) == pd.to_datetime(dates_assimilation[idx_date_update]):\n",
    "                # Perturb parameters according to the define mapping\n",
    "                if perturb_time:\n",
    "                    # Transform parameters for perturbation\n",
    "                    std_params = perturbation * cooling_factor[n]\n",
    "                    p_prior    = random_walk_perturbation(p_prior, std_params, if2_settings[\"num_params\"], if2_settings[\"num_ensembles\"])\n",
    "\n",
    "                # Inflate parameters\n",
    "                p_prior = inflate_ensembles(p_prior, inflation_value=if2_settings[\"lambda_inf\"], num_ensembles=if2_settings[\"num_ensembles\"])\n",
    "                p_prior = checkbound_params(param_prior_dict, p_prior, num_ensembles=if2_settings[\"num_ensembles\"])\n",
    "\n",
    "                # first adjust using only positives\n",
    "                oev_pos    = obs_w_chunk_df.loc[date][[f\"oev_{idx_chunk}\" for idx_chunk in range(abm_settings[\"num_clusters\"])]].values\n",
    "                pos_time   = obs_w_chunk_df.loc[date][[f\"pos_{idx_chunk}\" for idx_chunk in range(abm_settings[\"num_clusters\"])]].values\n",
    "\n",
    "                # then adjust using negatives\n",
    "                oev_neg    = neg_w_chunk_df.loc[date][[f\"oev_{idx_chunk}\" for idx_chunk in range(abm_settings[\"num_clusters\"])]].values\n",
    "                neg_time   = neg_w_chunk_df.loc[date][[f\"pos_{idx_chunk}\" for idx_chunk in range(abm_settings[\"num_clusters\"])]].values\n",
    "\n",
    "                param_post = p_prior.copy()\n",
    "\n",
    "                param_post, obs_post_pos = eakf_step_multi_obs(param_post, chunk_pos_t, np.expand_dims(pos_time, -1),  np.expand_dims(oev_pos, -1), param_prior_dict, int(if2_settings[\"num_observations\"] )) # Use both positives to adjust\n",
    "                param_post               = checkbound_params(param_prior_dict, params_ens=param_post, num_ensembles=if2_settings[\"num_ensembles\"])\n",
    "\n",
    "                param_post, obs_post_neg = eakf_step_multi_obs(param_post, chunk_neg_t, np.expand_dims(neg_time, -1),  np.expand_dims(oev_neg, -1), param_prior_dict, int(if2_settings[\"num_observations\"] )) # Use negatives to adjust\n",
    "                param_post               = checkbound_params(param_prior_dict, params_ens=param_post, num_ensembles=if2_settings[\"num_ensembles\"])\n",
    "\n",
    "                obs_post_time_pos[:, :, idx_date_update]    = obs_post_pos\n",
    "                obs_post_time_neg[:, :, idx_date_update]    = obs_post_neg\n",
    "\n",
    "                # Use posterior as next prior\n",
    "                p_prior                              = param_post.copy()\n",
    "                param_post_time[:,:,idx_date_update] = param_post\n",
    "                idx_date_update += 1\n",
    "\n",
    "                chunk_pos_t = np.zeros((abm_settings[\"num_clusters\"], if2_settings[\"num_ensembles\"]))\n",
    "                chunk_neg_t = np.zeros((abm_settings[\"num_clusters\"], if2_settings[\"num_ensembles\"]))\n",
    "\n",
    "        para_post_all[:,:,:,n]    = param_post_time\n",
    "        param_mean_iter[:,n+1]    = param_post_time.mean(-1).mean(-1)\n",
    "        obs_post_all_pos[:,:,:,n] = obs_post_time_pos\n",
    "        obs_post_all_neg[:,:,:,n] = obs_post_time_neg\n",
    "\n",
    "    return obs_w_chunk_df, neg_w_chunk_df, obs_post_all_pos, obs_post_all_neg, para_post_all, param_iter, param_mean_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "574dadffd7a64c0fd8dffb1c55414219139ca02322c8f7cd93c896672936a7f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
