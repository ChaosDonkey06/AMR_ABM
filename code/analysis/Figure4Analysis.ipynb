{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import truncnorm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import datetime\n",
    "import tqdm\n",
    "import sys\n",
    "import os\n",
    "\n",
    "def flatten_list(list_array):\n",
    "    return list(itertools.chain(*list_array))\n",
    "\n",
    "sys.path.insert(0,\"../\")\n",
    "from global_config import config\n",
    "\n",
    "results_dir           = config.get_property('results_dir')\n",
    "data_dir              = config.get_property('data_dir')\n",
    "data_db_dir           = config.get_property('data_db_dir')\n",
    "feb_hosp_records_path = os.path.join(data_db_dir, 'long_files_8_25_2021')\n",
    "path_to_save          = os.path.join(results_dir, \"real_testing\", \"community\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7p/jp6xqkvn5wb6ddl1fn0bhs980000gn/T/ipykernel_63586/1033347647.py:8: DtypeWarning: Columns (0,1,4,8) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  movement_df, ward2cluster = load_movement_df(path_to_data, True) # movement data\n"
     ]
    }
   ],
   "source": [
    "from utils.data_utils import load_movement_df, ward2size\n",
    "from utils.plot_utils import *\n",
    "\n",
    "path_to_data = os.path.join('..', '..', 'data')\n",
    "\n",
    "# load scenarios for synthetic inferences\n",
    "scenarios_df              = pd.read_csv(os.path.join(path_to_data, 'scenarios.csv'))\n",
    "movement_df, ward2cluster = load_movement_df(path_to_data, True) # movement data\n",
    "ward2size                 = ward2size(movement_df)\n",
    "ward2size                 = {r.ward_id: r.num_patients for idx_r, r in ward2size.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_min         = pd.to_datetime(\"2020-02-01\")\n",
    "date_max         = pd.to_datetime(\"2021-02-28\")\n",
    "dates_simulation = pd.date_range(start=date_min, end=date_max)\n",
    "\n",
    "γ_prior  = [0.01, 0.9]\n",
    "β_prior  = [0.001, 0.05]\n",
    "\n",
    "param_prior_dict      = {}\n",
    "param_prior_dict[\"γ\"] = γ_prior\n",
    "param_prior_dict[\"β\"] = β_prior\n",
    "\n",
    "# Agent based model settings.\n",
    "abm_settings                     = {}\n",
    "abm_settings[\"num_patients\"]     = movement_df.mrn_id.unique().shape[0]\n",
    "abm_settings[\"num_wards\"]        = movement_df.ward_id.unique().shape[0]\n",
    "abm_settings[\"num_clusters\"]     = len(set(list(ward2cluster.values())))\n",
    "abm_settings[\"dates\"]            = dates_simulation\n",
    "abm_settings[\"num_ensembles\"]    = 300\n",
    "\n",
    "# Iterated filtering settings.\n",
    "if2_settings                     = {}\n",
    "if2_settings[\"num_params\"]       = len(param_prior_dict)\n",
    "if2_settings[\"num_observations\"] = len(set(list(ward2cluster.values())))\n",
    "if2_settings[\"lambda_inf\"]       = 1.01        # Inflation for the EAKF.\n",
    "if2_settings[\"num_iters_mif\"]    = 20          # Number of iterations.\n",
    "if2_settings[\"alpha_mif\"]        = 0.8         # Variance shrinking factor.\n",
    "if2_settings[\"type_cooling\"]     = \"geometric\" # Type of cooling.\n",
    "if2_settings[\"num_ensembles\"]    = 300\n",
    "if2_settings[\"oev_variance\"]     = 0.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate scenarios for synthetic inferences\n",
    "Main manuscript uses 6% but 4% and 8% are used for sensitivity analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***-***-***-***-***-***\n",
      "Simulating model for scenario scenario1... ρ=6%\n",
      "***-***-***-***-***-***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "394it [13:06,  2.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***-***-***-***-***-***\n",
      "Simulating model for scenario scenario2... ρ=6%\n",
      "***-***-***-***-***-***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "394it [16:06,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***-***-***-***-***-***\n",
      "Simulating model for scenario scenario3... ρ=6%\n",
      "***-***-***-***-***-***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "394it [12:49,  1.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***-***-***-***-***-***\n",
      "Simulating model for scenario scenario4... ρ=6%\n",
      "***-***-***-***-***-***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "394it [12:55,  1.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***-***-***-***-***-***\n",
      "Simulating model for scenario scenario5... ρ=6%\n",
      "***-***-***-***-***-***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "394it [12:25,  1.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***-***-***-***-***-***\n",
      "Simulating model for scenario scenario6... ρ=6%\n",
      "***-***-***-***-***-***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "394it [33:45,  5.14s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***-***-***-***-***-***\n",
      "Simulating model for scenario scenario7... ρ=6%\n",
      "***-***-***-***-***-***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "394it [11:47,  1.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***-***-***-***-***-***\n",
      "Simulating model for scenario scenario8... ρ=6%\n",
      "***-***-***-***-***-***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "394it [13:07,  2.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***-***-***-***-***-***\n",
      "Simulating model for scenario scenario9... ρ=6%\n",
      "***-***-***-***-***-***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "394it [14:04,  2.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***-***-***-***-***-***\n",
      "Simulating model for scenario scenario10... ρ=6%\n",
      "***-***-***-***-***-***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "394it [13:26,  2.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***-***-***-***-***-***\n",
      "Simulating model for scenario scenario1... ρ=4%\n",
      "***-***-***-***-***-***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "394it [11:57,  1.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***-***-***-***-***-***\n",
      "Simulating model for scenario scenario2... ρ=4%\n",
      "***-***-***-***-***-***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "394it [11:29,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***-***-***-***-***-***\n",
      "Simulating model for scenario scenario3... ρ=4%\n",
      "***-***-***-***-***-***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "394it [11:38,  1.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***-***-***-***-***-***\n",
      "Simulating model for scenario scenario4... ρ=4%\n",
      "***-***-***-***-***-***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "394it [11:47,  1.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***-***-***-***-***-***\n",
      "Simulating model for scenario scenario5... ρ=4%\n",
      "***-***-***-***-***-***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "394it [11:16,  1.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***-***-***-***-***-***\n",
      "Simulating model for scenario scenario6... ρ=4%\n",
      "***-***-***-***-***-***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "394it [11:12,  1.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***-***-***-***-***-***\n",
      "Simulating model for scenario scenario7... ρ=4%\n",
      "***-***-***-***-***-***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "394it [11:04,  1.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***-***-***-***-***-***\n",
      "Simulating model for scenario scenario8... ρ=4%\n",
      "***-***-***-***-***-***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "394it [12:10,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***-***-***-***-***-***\n",
      "Simulating model for scenario scenario9... ρ=4%\n",
      "***-***-***-***-***-***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "394it [12:29,  1.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***-***-***-***-***-***\n",
      "Simulating model for scenario scenario10... ρ=4%\n",
      "***-***-***-***-***-***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "394it [13:15,  2.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***-***-***-***-***-***\n",
      "Simulating model for scenario scenario1... ρ=8%\n",
      "***-***-***-***-***-***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "394it [11:54,  1.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***-***-***-***-***-***\n",
      "Simulating model for scenario scenario2... ρ=8%\n",
      "***-***-***-***-***-***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "394it [11:31,  1.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***-***-***-***-***-***\n",
      "Simulating model for scenario scenario3... ρ=8%\n",
      "***-***-***-***-***-***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "394it [11:43,  1.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***-***-***-***-***-***\n",
      "Simulating model for scenario scenario4... ρ=8%\n",
      "***-***-***-***-***-***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "394it [11:49,  1.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***-***-***-***-***-***\n",
      "Simulating model for scenario scenario5... ρ=8%\n",
      "***-***-***-***-***-***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "394it [11:18,  1.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***-***-***-***-***-***\n",
      "Simulating model for scenario scenario6... ρ=8%\n",
      "***-***-***-***-***-***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "394it [11:18,  1.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***-***-***-***-***-***\n",
      "Simulating model for scenario scenario7... ρ=8%\n",
      "***-***-***-***-***-***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "394it [10:55,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***-***-***-***-***-***\n",
      "Simulating model for scenario scenario8... ρ=8%\n",
      "***-***-***-***-***-***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "394it [12:08,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***-***-***-***-***-***\n",
      "Simulating model for scenario scenario9... ρ=8%\n",
      "***-***-***-***-***-***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "394it [12:32,  1.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***-***-***-***-***-***\n",
      "Simulating model for scenario scenario10... ρ=8%\n",
      "***-***-***-***-***-***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "394it [13:16,  2.02s/it]\n"
     ]
    }
   ],
   "source": [
    "from utils.model_utils import simulate_model\n",
    "\n",
    "for ρ in [6, 4, 8]:\n",
    "    for idx_row, row in scenarios_df.iterrows():\n",
    "\n",
    "        θ      = {}\n",
    "        θ['γ'] = row['γ']\n",
    "        θ['β'] = row['β']\n",
    "        θ['ρ'] = ρ / 100\n",
    "\n",
    "        path_to_scenario = os.path.join('..', '..', 'results', 'synthetic_inferences', f'ρ_{ρ}%', row.name_scenario)\n",
    "        os.makedirs(path_to_scenario, exist_ok=True)\n",
    "        name_sims_save   = f\"simulation_infer.npz\"\n",
    "\n",
    "        #if os.path.isfile(os.path.join(path_to_scenario, name_sims_save)):\n",
    "        #    continue\n",
    "\n",
    "        print(\"***-***-***-***-***-***\")\n",
    "        print(f\"Simulating model for scenario {row.name_scenario}... ρ={ρ}%\")\n",
    "        print(\"***-***-***-***-***-***\")\n",
    "\n",
    "        ward_colonized, ward_nosocomial, ward_imported, ward_positive, ward_negative,\\\n",
    "        cluster_colonized, cluster_nosocomial, cluster_imported, cluster_positive, cluster_negative \\\n",
    "            = simulate_model(movement_df, ward2size, ward2cluster, θ, abm_settings)\n",
    "\n",
    "        positive_sim   = ward_positive.sum(-2)\n",
    "        idx_use        = np.argsort(np.sum(positive_sim, 0))[abm_settings[\"num_ensembles\"]//2]\n",
    "\n",
    "\n",
    "        np.savez_compressed(os.path.join(path_to_scenario, name_sims_save),\n",
    "                                        ward_colonized           = ward_colonized,\n",
    "                                        ward_nosocomial          = ward_nosocomial,\n",
    "                                        ward_imported            = ward_imported,\n",
    "                                        ward_positive            = ward_positive,\n",
    "                                        ward_negative            = ward_negative,\n",
    "                                        cluster_colonized        = cluster_colonized,\n",
    "                                        cluster_nosocomial       = cluster_nosocomial,\n",
    "                                        cluster_imported         = cluster_imported,\n",
    "                                        cluster_positive         = cluster_positive,\n",
    "                                        cluster_negative         = cluster_negative,\n",
    "                                        idx_use                  = idx_use)\n",
    "\n",
    "        #obs_w_chunk_df, neg_w_chunk_df = create_obs_infer(cluster_positive, cluster_negative, abm_settings, if2_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx_row, row in scenarios_df.iterrows():\n",
    "    θ      = {}\n",
    "    θ['γ'] = row['γ']\n",
    "    θ['β'] = row['β']\n",
    "    θ['ρ'] = ρ / 100\n",
    "\n",
    "    path_to_scenario = os.path.join('..', '..', 'results', 'synthetic_inferences', f'ρ_{ρ}%', row.name_scenario)\n",
    "    name_sims_save   = f\"simulation_infer.npz\"\n",
    "    sim_samples      = np.load(os.path.join(path_to_scenario, name_sims_save))\n",
    "\n",
    "    cluster_positive = sim_samples['cluster_positive'][:, :, sim_samples['idx_use']]\n",
    "    cluster_negative = sim_samples['cluster_negative'][:, :, sim_samples['idx_use']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IF2_eakf_ABM(data_infer, pos_obs_df, neg_obs_df, movement_df, param_prior, if2_settings, abm_settings, ward2cluster, ward2size, perturb_time=True, model=model_infer):\n",
    "\n",
    "    obs_w_chunk_df = pos_obs_df\n",
    "    neg_w_chunk_df = neg_obs_df\n",
    "    cooling_factor = cooling(if2_settings[\"num_iters_mif\"], type_cool=if2_settings[\"type_cooling\"], cooling_factor=if2_settings[\"alpha_mif\"])\n",
    "\n",
    "    param_range    = np.array([v for k, v in param_prior_dict.items()])\n",
    "    std_param      = param_range[:,1] - param_range[:,0]\n",
    "    SIG            = std_param ** 2 / 4; #  initial covariance of parameters\n",
    "\n",
    "    # Perturbation is proportional to the prior range of search.\n",
    "    perturbation     = np.array([std_param % list(np.round(std_param)+0.1)]).T\n",
    "    num_steps        = len(obs_w_chunk_df)\n",
    "\n",
    "    param_mean_iter  = np.full((if2_settings[\"num_params\"],       if2_settings[\"num_iters_mif\"]+1), np.nan)                                         # Array to store posterior parameters in iterations.\n",
    "    para_post_all    = np.full((if2_settings[\"num_params\"],       if2_settings[\"num_ensembles\"], num_steps, if2_settings[\"num_iters_mif\"]), np.nan) # Array to store posterior parameters.\n",
    "    param_iter       = np.full((if2_settings[\"num_params\"],       if2_settings[\"num_ensembles\"], if2_settings[\"num_iters_mif\"]), np.nan)\n",
    "\n",
    "    obs_post_all_pos = np.full((if2_settings[\"num_observations\"], if2_settings[\"num_ensembles\"], num_steps, if2_settings[\"num_iters_mif\"]), np.nan) # Array for store posterior observations\n",
    "    obs_post_all_neg = np.full((if2_settings[\"num_observations\"], if2_settings[\"num_ensembles\"], num_steps, if2_settings[\"num_iters_mif\"]), np.nan) # Array for store posterior observations\n",
    "    p_priors_all     = np.full((if2_settings[\"num_params\"],       if2_settings[\"num_ensembles\"], if2_settings[\"num_iters_mif\"]), np.nan)\n",
    "\n",
    "    dates_assimilation     = obs_w_chunk_df.index.get_level_values(0).values\n",
    "    dates_assimilation[-1] = abm_settings[\"dates\"][-1]\n",
    "\n",
    "    α            = np.random.uniform( 1/365, 1/175, size=(abm_settings[\"num_patients\"], if2_settings[\"num_ensembles\"]))\n",
    "    perturb_time = True\n",
    "\n",
    "    print(f\"Running MIF  \\n\")\n",
    "    for n in tqdm(range(if2_settings[\"num_iters_mif\"])):\n",
    "        if n==0: # Initial IF iteration\n",
    "            p_prior               = sample_params_uniform(param_prior_dict, num_ensembles=if2_settings[\"num_ensembles\"])\n",
    "            param_mean_iter[:, n] = np.mean(p_prior, -1)\n",
    "            p_priors_all[:,:,n]   = p_prior\n",
    "\n",
    "        else:\n",
    "            params_mean           = param_mean_iter[:,n]\n",
    "            params_var            = SIG * cooling_factor[n]\n",
    "            p_prior               = sample_params_normal(param_prior_dict, params_mean, params_var, num_ensembles=if2_settings[\"num_ensembles\"])\n",
    "            p_priors_all[:,:,n]   = p_prior\n",
    "\n",
    "        patients_state    = np.zeros((abm_settings[\"num_patients\"], if2_settings[\"num_ensembles\"]))\n",
    "        param_post_time   = np.full((if2_settings[\"num_params\"], if2_settings[\"num_ensembles\"], num_steps), np.nan)\n",
    "\n",
    "        obs_post_time_pos = np.full((abm_settings[\"num_clusters\"], if2_settings[\"num_ensembles\"], num_steps), np.nan)\n",
    "        obs_post_time_neg = np.full((abm_settings[\"num_clusters\"], if2_settings[\"num_ensembles\"], num_steps), np.nan)\n",
    "\n",
    "        idx_date_update   = 0\n",
    "\n",
    "        # Init observation arrays.\n",
    "        chunk_pos_t = np.zeros((abm_settings[\"num_clusters\"], if2_settings[\"num_ensembles\"]))\n",
    "        chunk_neg_t = np.zeros((abm_settings[\"num_clusters\"], if2_settings[\"num_ensembles\"]))\n",
    "\n",
    "        for idx_date, date in enumerate(abm_settings[\"dates\"]):\n",
    "            # Integrate model\n",
    "            γ = p_prior[0, :]\n",
    "            β = p_prior[1, :]\n",
    "\n",
    "            movement_date = movement_df.loc[date]\n",
    "            patients_state, _, chunk_pos, _, chunk_neg = model(patients_state, γ, β, α, movement_date, ward2size, ward2cluster)\n",
    "\n",
    "            chunk_pos_t += chunk_pos\n",
    "            chunk_neg_t += chunk_neg\n",
    "\n",
    "            if pd.to_datetime(date) == pd.to_datetime(dates_assimilation[idx_date_update]):\n",
    "                # Perturb parameters according to the define mapping\n",
    "                if perturb_time:\n",
    "                    # Transform parameters for perturbation\n",
    "                    std_params = perturbation * cooling_factor[n]\n",
    "                    p_prior    = random_walk_perturbation(p_prior, std_params, if2_settings[\"num_params\"], if2_settings[\"num_ensembles\"])\n",
    "\n",
    "                # Inflate parameters\n",
    "                p_prior = inflate_ensembles(p_prior, inflation_value=if2_settings[\"lambda_inf\"], num_ensembles=if2_settings[\"num_ensembles\"])\n",
    "                p_prior = checkbound_params(param_prior_dict, p_prior, num_ensembles=if2_settings[\"num_ensembles\"])\n",
    "\n",
    "                # first adjust using only positives\n",
    "                oev_pos    = obs_w_chunk_df.loc[date][[f\"oev_{idx_chunk}\" for idx_chunk in range(abm_settings[\"num_clusters\"])]].values\n",
    "                pos_time   = obs_w_chunk_df.loc[date][[f\"pos_{idx_chunk}\" for idx_chunk in range(abm_settings[\"num_clusters\"])]].values\n",
    "\n",
    "                # then adjust using negatives\n",
    "                oev_neg    = neg_w_chunk_df.loc[date][[f\"oev_{idx_chunk}\" for idx_chunk in range(abm_settings[\"num_clusters\"])]].values\n",
    "                neg_time   = neg_w_chunk_df.loc[date][[f\"pos_{idx_chunk}\" for idx_chunk in range(abm_settings[\"num_clusters\"])]].values\n",
    "\n",
    "                param_post = p_prior.copy()\n",
    "\n",
    "\n",
    "                param_post, obs_post_pos = eakf_step_multi_obs(param_post, chunk_pos_t, np.expand_dims(pos_time, -1),  np.expand_dims(oev_pos, -1), param_prior_dict, int(if2_settings[\"num_observations\"] )) # Use both positives to adjust\n",
    "                param_post               = checkbound_params(param_prior_dict, params_ens=param_post, num_ensembles=if2_settings[\"num_ensembles\"])\n",
    "\n",
    "                param_post, obs_post_neg = eakf_step_multi_obs(param_post, chunk_neg_t, np.expand_dims(neg_time, -1),  np.expand_dims(oev_neg, -1), param_prior_dict, int(if2_settings[\"num_observations\"] )) # Use negatives to adjust\n",
    "                param_post               = checkbound_params(param_prior_dict, params_ens=param_post, num_ensembles=if2_settings[\"num_ensembles\"])\n",
    "                obs_post_time_pos[:, :, idx_date_update]    = obs_post_pos\n",
    "                obs_post_time_neg[:, :, idx_date_update]    = obs_post_neg\n",
    "\n",
    "                # Use posterior as next prior\n",
    "                p_prior = param_post.copy()\n",
    "                param_post_time[:,:,idx_date_update]  = param_post\n",
    "                idx_date_update += 1\n",
    "\n",
    "                chunk_pos_t = np.zeros((abm_settings[\"num_clusters\"], if2_settings[\"num_ensembles\"]))\n",
    "                chunk_neg_t = np.zeros((abm_settings[\"num_clusters\"], if2_settings[\"num_ensembles\"]))\n",
    "\n",
    "        para_post_all[:,:,:,n]    = param_post_time\n",
    "        param_mean_iter[:,n+1]    = param_post_time.mean(-1).mean(-1)\n",
    "        obs_post_all_pos[:,:,:,n] = obs_post_time_pos\n",
    "        obs_post_all_neg[:,:,:,n] = obs_post_time_neg\n",
    "\n",
    "    return obs_w_chunk_df, neg_w_chunk_df, obs_post_all_pos, obs_post_all_neg, para_post_all, param_iter, param_mean_iter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "574dadffd7a64c0fd8dffb1c55414219139ca02322c8f7cd93c896672936a7f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
