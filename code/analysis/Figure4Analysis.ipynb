{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import truncnorm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import datetime\n",
    "import tqdm\n",
    "import sys\n",
    "import os\n",
    "\n",
    "def flatten_list(list_array):\n",
    "    return list(itertools.chain(*list_array))\n",
    "\n",
    "sys.path.insert(0,\"../\")\n",
    "from global_config import config\n",
    "\n",
    "results_dir           = config.get_property('results_dir')\n",
    "data_dir              = config.get_property('data_dir')\n",
    "data_db_dir           = config.get_property('data_db_dir')\n",
    "feb_hosp_records_path = os.path.join(data_db_dir, 'long_files_8_25_2021')\n",
    "path_to_save          = os.path.join(results_dir, \"real_testing\", \"community\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7p/jp6xqkvn5wb6ddl1fn0bhs980000gn/T/ipykernel_94414/1923229292.py:8: DtypeWarning: Columns (0,1,4,8) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  movement_df, ward2cluster = load_movement_df(path_to_data, True) # movement data\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7p/jp6xqkvn5wb6ddl1fn0bhs980000gn/T/ipykernel_94414/1923229292.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# load scenarios for synthetic inferences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mscenarios_df\u001b[0m              \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'scenarios.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmovement_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mward2cluster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_movement_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# movement data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mward2size\u001b[0m                 \u001b[0;34m=\u001b[0m \u001b[0mward2size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovement_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/My Mac (Jaimes-MacBook-Pro.local)/Desktop/Shaman-lab/AMR_ABM/code/utils/data_utils.py\u001b[0m in \u001b[0;36mload_movement_df\u001b[0;34m(path_to_movement_data, return_ward)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mid2mrn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_movement_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"mrn2id.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mid2mrn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrn_id\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrn\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mid2mrn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mmovement_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mrn\"\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mmovement_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mrn_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid2mrn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/My Mac (Jaimes-MacBook-Pro.local)/Desktop/Shaman-lab/AMR_ABM/code/utils/data_utils.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mid2mrn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_movement_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"mrn2id.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mid2mrn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrn_id\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrn\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mid2mrn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mmovement_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mrn\"\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mmovement_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mrn_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid2mrn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5484\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5485\u001b[0m         ):\n\u001b[0;32m-> 5486\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5487\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3359\u001b[0m             \u001b[0mcasted_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from utils.data_utils import load_movement_df, ward2size\n",
    "from utils.plot_utils import *\n",
    "\n",
    "path_to_data = os.path.join('..', '..', 'data')\n",
    "\n",
    "# load scenarios for synthetic inferences\n",
    "scenarios_df              = pd.read_csv(os.path.join(path_to_data, 'scenarios.csv'))\n",
    "movement_df, ward2cluster = load_movement_df(path_to_data, True) # movement data\n",
    "ward2size                 = ward2size(movement_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_min         = pd.to_datetime(\"2020-02-01\")\n",
    "date_max         = pd.to_datetime(\"2021-02-28\")\n",
    "dates_simulation = pd.date_range(start=date_min, end=date_max)\n",
    "\n",
    "γ_prior  = [0.01, 0.9]\n",
    "β_prior  = [0.001, 0.05]\n",
    "\n",
    "param_prior_dict      = {}\n",
    "param_prior_dict[\"γ\"] = γ_prior\n",
    "param_prior_dict[\"β\"] = β_prior\n",
    "\n",
    "# Agent based model settings.\n",
    "abm_settings                     = {}\n",
    "abm_settings[\"num_patients\"]     = movement_df.mrn_id.unique().shape[0]\n",
    "abm_settings[\"num_wards\"]        = movement_df.ward_id.unique().shape[0]\n",
    "abm_settings[\"num_clusters\"]     = len(set(list(ward2cluster.values())))\n",
    "abm_settings[\"dates\"]            = dates_simulation\n",
    "abm_settings[\"num_ensembles\"]    = 300\n",
    "\n",
    "# Iterated filtering settings.\n",
    "if2_settings                     = {}\n",
    "if2_settings[\"num_params\"]       = len(param_prior_dict)\n",
    "if2_settings[\"num_observations\"] = len(set(list(ward2cluster.values())))\n",
    "if2_settings[\"lambda_inf\"]       = 1.01        # Inflation for the EAKF.\n",
    "if2_settings[\"num_iters_mif\"]    = 20          # Number of iterations.\n",
    "if2_settings[\"alpha_mif\"]        = 0.8         # Variance shrinking factor.\n",
    "if2_settings[\"type_cooling\"]     = \"geometric\" # Type of cooling.\n",
    "if2_settings[\"num_ensembles\"]    = 300\n",
    "if2_settings[\"oev_variance\"]     = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate scenarios for synthetic inferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.model_utils import simulate_model\n",
    "\n",
    "for idx_row, row in scenarios_df.iterrows():\n",
    "\n",
    "    θ = {}\n",
    "    θ['γ'] = row['γ']\n",
    "    θ['β'] = row['β']\n",
    "\n",
    "    print(\"***-***-***-***-***-***\")\n",
    "    print(\"Simulating model...\")\n",
    "    ward_colonized, ward_nosocomial, ward_colonized_imported, ward_positive, ward_negative,\\\n",
    "    cluster_colonized, cluster_nosocomial, cluster_colonized_imported, cluster_positive, cluster_negative \\\n",
    "        = simulate_model(movement_df, ward2size, ward2cluster, θ, abm_settings)\n",
    "\n",
    "    print(\"***-***-***-***-***-***\")\n",
    "\n",
    "\n",
    "    positive_sim   = ward_pos_sim.sum(-2)\n",
    "    idx_use        = np.argsort(np.sum(positive_sim, 0))[abm_settings[\"num_ensembles\"]//2]\n",
    "    name_sims_save = f\"simulation_infer.npz\"\n",
    "\n",
    "    np.savez_compressed(os.path.join('..', '..', 'results', 'synthetic_inferences', name_sims_save),\n",
    "                                    positive                 = positive_sim,\n",
    "                                    ward_colonized           = ward_colonized_sim,\n",
    "                                    ward_nosocomial          = ward_nosocomial_sim,\n",
    "                                    ward_colonized_imported  = ward_col_imp_sim,\n",
    "                                    ward_positive            = ward_pos_sim,\n",
    "                                    chunk_colonized          = chunk_colonized_sim,\n",
    "                                    chunk_nosocomial         = chunk_nosocomial_sim,\n",
    "                                    chunk_colonized_imported = chunk_col_imp_sim,\n",
    "                                    chunk_positive           = chunk_pos_sim,\n",
    "                                    idx_use                  = idx_use)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from utils_inference2 import compute_sen_oev, sample_params_uniform, sample_params_normal, cooling, random_walk_perturbation, inflate_ensembles, checkbound_params, eakf_step_multi_obs\n",
    "def create_obs_infer(data_infer, abm_settings):\n",
    "    # Create population level observations\n",
    "    obs_pop_df                       = pd.DataFrame(columns=[\"date\", \"positives\", \"negatives\"])\n",
    "    obs_pop_df[\"date\"]               = abm_settings[\"dates\"]\n",
    "    obs_pop_df[\"positives\"]          = data_infer.pos_obs\n",
    "    obs_pop_df[\"negatives\"]          = data_infer.neg_obs\n",
    "\n",
    "    # Resample every week\n",
    "    obs_w_pop_df         = obs_pop_df.set_index(\"date\").resample(\"W-Sun\").sum()\n",
    "    obs_w_pop_df[\"oev\"]  = compute_sen_oev(obs_w_pop_df[\"positives\"], var_obs=if2_settings[\"oev_variance\"])\n",
    "    obs_w_pop_df[\"oev\"]  = np.minimum(obs_w_pop_df[\"oev\"], 50*7)\n",
    "\n",
    "    # Create ward chunks level observations\n",
    "    obs_chunk_df         = pd.DataFrame(columns=[\"date\"] + [f\"pos_{idx_chunk}\" for idx_chunk in range(abm_settings[\"num_clusters\"])])\n",
    "    obs_chunk_df[\"date\"] = abm_settings[\"dates\"]\n",
    "\n",
    "    neg_chunk_df         = pd.DataFrame(columns=[\"date\"] + [f\"pos_{idx_chunk}\" for idx_chunk in range(abm_settings[\"num_clusters\"])])\n",
    "    neg_chunk_df[\"date\"] = abm_settings[\"dates\"]\n",
    "\n",
    "    for idx_chunk in range(abm_settings[\"num_clusters\"]):\n",
    "        obs_chunk_df[f\"pos_{idx_chunk}\"] = ward_pos_obs[:, idx_chunk]\n",
    "        neg_chunk_df[f\"pos_{idx_chunk}\"] = ward_neg_obs[:, idx_chunk]\n",
    "\n",
    "    # Resample every week\n",
    "    obs_w_chunk_df         = obs_chunk_df.set_index(\"date\").resample(\"W-Sun\").sum()\n",
    "    neg_w_chunk_df         = neg_chunk_df.set_index(\"date\").resample(\"W-Sun\").sum()\n",
    "\n",
    "    for idx_chunk in range(abm_settings[\"num_clusters\"]):\n",
    "        obs_w_chunk_df[f\"oev_{idx_chunk}\"]  = compute_sen_oev(obs_w_chunk_df[f\"pos_{idx_chunk}\"] , var_obs=0.2)\n",
    "        obs_w_chunk_df[f\"oev_{idx_chunk}\"]  = np.minimum(obs_w_chunk_df[f\"oev_{idx_chunk}\"], 50*7)\n",
    "        neg_w_chunk_df[f\"oev_{idx_chunk}\"]  = compute_sen_oev(neg_w_chunk_df[f\"pos_{idx_chunk}\"] , var_obs=0.2)\n",
    "        neg_w_chunk_df[f\"oev_{idx_chunk}\"]  = np.minimum(neg_w_chunk_df[f\"oev_{idx_chunk}\"], 50*7)\n",
    "\n",
    "    return obs_w_chunk_df, neg_w_chunk_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IF2_eakf_ABM(data_infer, model_infer, movement_df, param_prior, if2_settings, abm_settings, scenario_params, ward2community_dict, ward2size_dict, perturb_time=True, path_to_save=None, run_id=None, sequential=True):\n",
    "\n",
    "    obs_w_chunk_df, neg_w_chunk_df = create_obs_infer(data_infer, abm_settings)\n",
    "\n",
    "    cooling_factor   = cooling(if2_settings[\"num_iters_mif\"], type_cool=if2_settings[\"type_cooling\"], cooling_factor=if2_settings[\"alpha_mif\"])\n",
    "\n",
    "    param_range      = np.array([v for k, v in param_prior_dict.items()])\n",
    "    std_param        = param_range[:,1] - param_range[:,0]\n",
    "    SIG              = std_param ** 2 / 4; #  initial covariance of parameters\n",
    "\n",
    "    # Perturbation is proportional to the prior range of search.\n",
    "    perturbation     = np.array([std_param % list(np.round(std_param)+0.1)]).T\n",
    "    num_steps        = len(obs_w_chunk_df)\n",
    "\n",
    "    param_mean_iter  = np.full((if2_settings[\"num_params\"],       if2_settings[\"num_iters_mif\"]+1), np.nan)                                         # Array to store posterior parameters in iterations.\n",
    "    para_post_all    = np.full((if2_settings[\"num_params\"],       if2_settings[\"num_ensembles\"], num_steps, if2_settings[\"num_iters_mif\"]), np.nan) # Array to store posterior parameters.\n",
    "    param_iter       = np.full((if2_settings[\"num_params\"],       if2_settings[\"num_ensembles\"], if2_settings[\"num_iters_mif\"]), np.nan)\n",
    "\n",
    "    if sequential:\n",
    "        obs_post_all_pos     = np.full((if2_settings[\"num_observations\"], if2_settings[\"num_ensembles\"], num_steps, if2_settings[\"num_iters_mif\"]), np.nan) # Array for store posterior observations\n",
    "        obs_post_all_neg     = np.full((if2_settings[\"num_observations\"], if2_settings[\"num_ensembles\"], num_steps, if2_settings[\"num_iters_mif\"]), np.nan) # Array for store posterior observations\n",
    "\n",
    "    else:\n",
    "        obs_post_all   = np.full((if2_settings[\"num_observations\"]*2, if2_settings[\"num_ensembles\"], num_steps, if2_settings[\"num_iters_mif\"]), np.nan) # Array for store posterior observations\n",
    "\n",
    "    p_priors_all       = np.full((if2_settings[\"num_params\"],       if2_settings[\"num_ensembles\"], if2_settings[\"num_iters_mif\"]), np.nan)\n",
    "\n",
    "    dates_assimilation     = obs_w_chunk_df.index.get_level_values(0).values\n",
    "    dates_assimilation[-1] = abm_settings[\"dates\"][-1]\n",
    "\n",
    "    alpha_ens    = np.random.uniform( 1/365, 1/175, size=(abm_settings[\"num_patients\"], if2_settings[\"num_ensembles\"]))\n",
    "    perturb_time = True\n",
    "\n",
    "    print(f\"Running MIF  \\n\")\n",
    "    for n in tqdm(range(if2_settings[\"num_iters_mif\"])):\n",
    "        if n==0: # Initial IF iteration\n",
    "\n",
    "            p_prior               = sample_params_uniform(param_prior_dict, num_ensembles=if2_settings[\"num_ensembles\"])\n",
    "            param_mean_iter[:, n] = np.mean(p_prior, -1)\n",
    "            p_priors_all[:,:,n]   = p_prior\n",
    "\n",
    "        else:\n",
    "            params_mean           = param_mean_iter[:,n]\n",
    "            params_var            = SIG * cooling_factor[n]\n",
    "            p_prior               = sample_params_normal(param_prior_dict, params_mean, params_var, num_ensembles=if2_settings[\"num_ensembles\"])\n",
    "            p_priors_all[:,:,n]   = p_prior\n",
    "\n",
    "        patients_state    = np.zeros((abm_settings[\"num_patients\"], if2_settings[\"num_ensembles\"]))\n",
    "\n",
    "        param_post_time   = np.full((if2_settings[\"num_params\"], if2_settings[\"num_ensembles\"], num_steps), np.nan)\n",
    "\n",
    "        if sequential:\n",
    "            obs_post_time_pos     = np.full((abm_settings[\"num_wards_chunks\"], if2_settings[\"num_ensembles\"], num_steps), np.nan)\n",
    "            obs_post_time_neg     = np.full((abm_settings[\"num_wards_chunks\"], if2_settings[\"num_ensembles\"], num_steps), np.nan)\n",
    "\n",
    "        else:\n",
    "            obs_post_time     = np.full((abm_settings[\"num_wards_chunks\"]*2, if2_settings[\"num_ensembles\"], num_steps), np.nan)\n",
    "\n",
    "        idx_date_update   = 0\n",
    "\n",
    "        # Init observation arrays.\n",
    "        chunk_pos_t = np.zeros((abm_settings[\"num_wards_chunks\"], if2_settings[\"num_ensembles\"]))\n",
    "        chunk_neg_t = np.zeros((abm_settings[\"num_wards_chunks\"], if2_settings[\"num_ensembles\"]))\n",
    "\n",
    "        for idx_date, date in enumerate(abm_settings[\"dates\"]):\n",
    "            #print(date)\n",
    "\n",
    "            # Integrate model\n",
    "            gamma_ens = p_prior[0, :]\n",
    "            beta_ens  = p_prior[1, :]\n",
    "\n",
    "            movement_date = movement_df.loc[date]\n",
    "            patients_state, _, chunk_pos, _, chunk_neg = model_infer(patients_state, gamma_ens, beta_ens, alpha_ens, movement_date, ward_id2size, ward2community_dict)\n",
    "\n",
    "            chunk_pos_t += chunk_pos\n",
    "            chunk_neg_t += chunk_neg\n",
    "\n",
    "            if pd.to_datetime(date) == pd.to_datetime(dates_assimilation[idx_date_update]):\n",
    "                # Perturb parameters according to the define mapping\n",
    "                if perturb_time:\n",
    "                    # Transform parameters for perturbation\n",
    "                    std_params = perturbation * cooling_factor[n]\n",
    "                    p_prior    = random_walk_perturbation(p_prior, std_params, if2_settings[\"num_params\"], if2_settings[\"num_ensembles\"])\n",
    "\n",
    "                # Inflate parameters\n",
    "                p_prior = inflate_ensembles(p_prior, inflation_value=if2_settings[\"lambda_inf\"], num_ensembles=if2_settings[\"num_ensembles\"])\n",
    "                p_prior = checkbound_params(param_prior_dict, p_prior, num_ensembles=if2_settings[\"num_ensembles\"])\n",
    "\n",
    "                # first adjust using only positives\n",
    "                oev_pos   = obs_w_chunk_df.loc[date][[f\"oev_{idx_chunk}\" for idx_chunk in range(abm_settings[\"num_wards_chunks\"])]].values\n",
    "                pos_time  = obs_w_chunk_df.loc[date][[f\"pos_{idx_chunk}\" for idx_chunk in range(abm_settings[\"num_wards_chunks\"])]].values\n",
    "\n",
    "                # then adjust using negatives\n",
    "                oev_neg   = neg_w_chunk_df.loc[date][[f\"oev_{idx_chunk}\" for idx_chunk in range(abm_settings[\"num_wards_chunks\"])]].values\n",
    "                neg_time  = neg_w_chunk_df.loc[date][[f\"pos_{idx_chunk}\" for idx_chunk in range(abm_settings[\"num_wards_chunks\"])]].values\n",
    "\n",
    "                param_post               = p_prior.copy()\n",
    "\n",
    "                if sequential:\n",
    "\n",
    "                    param_post, obs_post_pos = eakf_step_multi_obs(param_post, chunk_pos_t, np.expand_dims(pos_time, -1),  np.expand_dims(oev_pos, -1), param_prior_dict, int(if2_settings[\"num_observations\"] )) # Use both positives to adjust\n",
    "                    param_post               = checkbound_params(param_prior_dict, params_ens=param_post, num_ensembles=if2_settings[\"num_ensembles\"])\n",
    "\n",
    "                    param_post, obs_post_neg = eakf_step_multi_obs(param_post, chunk_neg_t, np.expand_dims(neg_time, -1),  np.expand_dims(oev_neg, -1), param_prior_dict, int(if2_settings[\"num_observations\"] )) # Use negatives to adjust\n",
    "                    param_post               = checkbound_params(param_prior_dict, params_ens=param_post, num_ensembles=if2_settings[\"num_ensembles\"])\n",
    "                    obs_post_time_pos[:,:,idx_date_update]    = obs_post_pos\n",
    "                    obs_post_time_neg[:,:,idx_date_update]    = obs_post_neg\n",
    "\n",
    "                else:\n",
    "                    obs_ens_time             = np.concatenate([chunk_pos_t, chunk_neg_t])\n",
    "                    obs_time                 = np.concatenate([pos_time, neg_time])\n",
    "                    oev_time                 = np.concatenate([oev_pos, oev_neg])\n",
    "\n",
    "                    param_post, obs_post     = eakf_step_multi_obs(param_post, obs_ens_time, np.expand_dims(obs_time, -1),  np.expand_dims(oev_time, -1), param_prior_dict, int(if2_settings[\"num_observations\"]*2 )) # Use both positives and negatives in the inference.\n",
    "                    param_post               = checkbound_params(param_prior_dict, params_ens=param_post, num_ensembles=if2_settings[\"num_ensembles\"])\n",
    "                    obs_post_time[:,:,idx_date_update]    = obs_post\n",
    "\n",
    "                # Use posterior as next prior\n",
    "                p_prior = param_post.copy()\n",
    "                param_post_time[:,:,idx_date_update]  = param_post\n",
    "\n",
    "                idx_date_update += 1\n",
    "\n",
    "                chunk_pos_t = np.zeros((abm_settings[\"num_wards_chunks\"], if2_settings[\"num_ensembles\"]))\n",
    "                chunk_neg_t = np.zeros((abm_settings[\"num_wards_chunks\"], if2_settings[\"num_ensembles\"]))\n",
    "\n",
    "        para_post_all[:,:,:,n]    = param_post_time\n",
    "        param_mean_iter[:,n+1]    = param_post_time.mean(-1).mean(-1)\n",
    "\n",
    "        obs_post_all_pos[:,:,:,n] = obs_post_time_pos\n",
    "        obs_post_all_neg[:,:,:,n] = obs_post_time_neg\n",
    "\n",
    "    return obs_w_chunk_df, neg_w_chunk_df, obs_post_all_pos, obs_post_all_neg, para_post_all, param_iter, param_mean_iter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "574dadffd7a64c0fd8dffb1c55414219139ca02322c8f7cd93c896672936a7f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
